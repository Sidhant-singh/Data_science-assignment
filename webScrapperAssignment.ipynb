{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nQ1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\\nWeb scraping is automated extraction of data from websites. \\nIt's used for efficiency in collecting information. \\nThree areas include business research, price monitoring, and content aggregation.\\n\\nQ2. What are the different methods used for Web Scraping?\\nMethods include manual scraping, regular expressions, \\nDOM parsing, web scraping libraries (e.g., Beautiful Soup), \\nand headless browsing with tools like Selenium.\\n\\n\\nQ3. What is Beautiful Soup? Why is it used?\\nBeautiful Soup is a Python library for parsing HTML and XML. \\nIt simplifies navigation of HTML structures, making it easier to extract data during web scraping.\\n\\nQ4. Why is Flask used in this Web Scraping project?\\nFlask is a lightweight web framework for Python. \\nIt can be used to build a web interface, present scraped data, create API endpoints, and integrate with other Python libraries.\\n\\n\\nQ5. Write the names of AWS services used in this project. Also, explain the use of each service.\\nAmazon EC2: Hosts web scraping scripts.\\nAmazon S3: Stores and manages scraped data.\\nAWS Lambda: Executes periodic web scraping tasks.\\nAmazon RDS: Stores structured data in a relational database.\\nAmazon API Gateway: Creates, publishes, and manages APIs.\\nAmazon CloudWatch: Monitors and logs the performance of the web scraping application.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "Web scraping is automated extraction of data from websites. \n",
    "It's used for efficiency in collecting information. \n",
    "Three areas include business research, price monitoring, and content aggregation.\n",
    "\n",
    "Q2. What are the different methods used for Web Scraping?\n",
    "Methods include manual scraping, regular expressions, \n",
    "DOM parsing, web scraping libraries (e.g., Beautiful Soup), \n",
    "and headless browsing with tools like Selenium.\n",
    "\n",
    "\n",
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "Beautiful Soup is a Python library for parsing HTML and XML. \n",
    "It simplifies navigation of HTML structures, making it easier to extract data during web scraping.\n",
    "\n",
    "Q4. Why is Flask used in this Web Scraping project?\n",
    "Flask is a lightweight web framework for Python. \n",
    "It can be used to build a web interface, present scraped data, create API endpoints, and integrate with other Python libraries.\n",
    "\n",
    "\n",
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "Amazon EC2: Hosts web scraping scripts.\n",
    "Amazon S3: Stores and manages scraped data.\n",
    "AWS Lambda: Executes periodic web scraping tasks.\n",
    "Amazon RDS: Stores structured data in a relational database.\n",
    "Amazon API Gateway: Creates, publishes, and manages APIs.\n",
    "Amazon CloudWatch: Monitors and logs the performance of the web scraping application.\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
